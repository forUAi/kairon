Key Features 
âœ… Double-Entry Accounting: Every transaction creates matching debit/credit events
âœ… Event Sourcing: Immutable event log with full audit trail
âœ… REST API: FastAPI with endpoints for transfers, balances, and events
âœ… PostgreSQL Backend: Optimized schema with proper indexes
âœ… Comprehensive Testing: Unit, integration, and API tests
âœ… Docker Support: Ready-to-run with docker-compose
âœ… Modular Architecture: Clean separation of concerns
ğŸ—ï¸ Architecture Highlights

Command Processor: Validates all business rules before execution
Event Store: Immutable append-only event logging
Projection Engine: Real-time balance updates from events
Repository Pattern: Clean data access abstractions
Transaction Safety: ACID compliance with PostgreSQL transactions

# Clone and setup
git clone <your-repo>
cd ledger-system
cp .env.example .env

# Start with Docker
docker-compose up -d

# Seed test data
python scripts/seed_data.py

# Run tests
pytest tests/ -v

# Access API docs
open http://localhost:8000/docs

Business Rules Enforced

âœ… Double-entry: Every debit has matching credit
âœ… No overdrafts (configurable)
âœ… Currency validation
âœ… Atomic transactions
âœ… Account existence validation
âœ… Positive amounts only

ğŸ“Š Sample Data Flow
The seed script demonstrates the three scenarios you requested:

Internal Float â†’ Alice (500 USD funding)
Alice â†’ Bob (100 USD payment)
Bob â†’ Alice (50 USD refund)

This creates a complete audit trail with proper double-entry bookkeeping!


ğŸ“š API Documentation
Example API Calls
##Create Account
bash
curl -X POST "http://localhost:8000/ledger/account/" \
  -H "Content-Type: application/json" \
  -d '{
    "currency": "USD",
    "type": "user",
    "metadata": {"name": "John Doe"}
  }'
  
##Transfer Funds
bash
curl -X POST "http://localhost:8000/ledger/transfer/" \
  -H "Content-Type: application/json" \
  -d '{
    "source_account_id": "550e8400-e29b-41d4-a716-446655440000",
    "destination_account_id": "550e8400-e29b-41d4-a716-446655440001",
    "amount": "100.50",
    "currency": "USD",
    "metadata": {"description": "Payment for services"}
  }'
  
##Get Account Balance
bash
curl "http://localhost:8000/ledger/account/550e8400-e29b-41d4-a716-446655440000/balance"

##Get Account Events
bash
curl "http://localhost:8000/ledger/events/?account_id=550e8400-e29b-41d4-a716-446655440000&limit=50"

ğŸš€ Getting Started

Setup Environment
bash
cp .env.example .env

# Edit .env with your configuration

Start with Docker
bashdocker-compose up -d

Run Migrations
bash# Migrations run automatically with docker-compose
# Or manually: psql -U ledger_user -d ledger_db -f app/database/migrations/001_initial_schema.sql

Seed Data
bashpython scripts/seed_data.py

Run Tests
bashpytest tests/ -v

Access API Documentation

OpenAPI/Swagger: http://localhost:8000/docs
ReDoc: http://localhost:8000/redoc


# ğŸ§  Recon Engine â€“ Modular Reconciliation System

A high-performance, event-sourced reconciliation engine designed for financial infrastructure. Built to compare external transactions (bank, CSV, API) with internal ledger events, detect mismatches, and generate a complete audit trail â€” with APIs, match scoring, summaries, and automation built-in.

---

## âœ… Key Features

- âœ… **Multi-Source Reconciliation**: Supports CSV, API, and custom source adapters
- âœ… **Event-Sourced Ledger Integration**: Designed to work with append-only double-entry ledgers
- âœ… **Matching Engine**: Exact + Fuzzy logic with configurable thresholds
- âœ… **FastAPI-Driven**: Rich APIs for triggering, monitoring, and debugging reconciliation jobs
- âœ… **PostgreSQL Backend**: Optimized schema with job tracking and log indexing
- âœ… **Job Scheduler**: Auto-runs reconciliation daily at a defined hour
- âœ… **Modular CLI**: Manually trigger reconciliation from the terminal
- âœ… **Async Python**: Built fully with `asyncio`, `asyncpg`, and `FastAPI`
- âœ… **Comprehensive Testing**: Unit tests for matchers + integration tests for full job flow

---

## ğŸ—ï¸ Architecture Highlights

| Component           | Role |
|---------------------|------|
| `ReconEngine`       | Orchestrates job lifecycle: load, match, log, finalize |
| `LedgerReader`      | Pulls internal transactions from the smart ledger |
| `CSVReader` / `APIAdapter` | Pulls external records |
| `ExactMatcher`      | Direct match by txn_id, amount, timestamp |
| `FuzzyMatcher`      | Threshold-based matching with scoring |
| `ReconLogger`       | Logs matches, updates jobs, writes summary |
| `FastAPI Router`    | Provides `/run`, `/status`, `/logs`, `/summary` |
| `Scheduler`         | Async loop to run jobs daily at configured hour |
| `PostgreSQL`        | Stores jobs, logs, summaries |
| `CLI Tool`          | One-liner trigger: `python cli.py run-recon --source ...` |

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone & Setup

```bash
git clone https://github.com/your-org/recon_engine.git
cd recon_engine
cp .env.example .env

2ï¸âƒ£ Start with Docker
bash
Copy
Edit
docker-compose up -d
Runs API server + Postgres + Alembic migrations.

3ï¸âƒ£ Run Migrations (if manual)
bash
Copy
Edit
psql -U postgres -d recon_db -f recon_engine/database/schema.sql
ğŸ§ª Run Reconciliation via CLI
bash
Copy
Edit
python recon_engine/cli.py run-recon \
  --source bank_csv \
  --date 2025-07-13 \
  --file_path ./data/bank_dump.csv
âš™ï¸ API Endpoints
âœ… Trigger Reconciliation
bash
Copy
Edit
curl -X POST "http://localhost:8000/recon/run" \
  -H "Content-Type: application/json" \
  -d '{ "source": "bank_csv", "date": "2025-07-13" }'
âœ… Get Job Status
bash
Copy
Edit
curl http://localhost:8000/recon/status/2025-07-13
âœ… View Logs (Matched/Unmatched)
bash
Copy
Edit
curl "http://localhost:8000/recon/logs?source=bank_csv&date=2025-07-13&matched=false"
âœ… Job Summary
bash
Copy
Edit
curl http://localhost:8000/recon/summary/2025-07-13
ğŸ§ª Testing
Run Tests
bash
Copy
Edit
pytest tests/ -v
Tests include:

âœ… test_matchers.py: Exact & fuzzy matcher logic

âœ… test_recon_engine.py: Full job flow with mocks

ğŸ’¡ Business Rules Enforced
âœ… Txn IDs must match or pass fuzzy scoring threshold

âœ… Amounts must be within allowed_amount_diff

âœ… Timestamps must be within max_time_diff_minutes

âœ… Only supported currencies are accepted

âœ… All results logged for compliance and auditability

ğŸ“Š Sample Data Flow
text
Copy
Edit
ğŸ” External CSV (bank) with 3 txns
ğŸ” Internal ledger with 3 events

ğŸ¯ ReconEngine:
  â†’ Matches 2 exactly
  â†’ Fuzzy matches 1 with score 0.87

ğŸ§¾ Logs written to recon_logs
ğŸ“Š Summary written to recon_summary
ğŸ“¥ Job status updated in recon_jobs
ğŸ›¡ï¸ Security and Compliance
ğŸ”’ Full audit trail per job (immutable log records)

ğŸ” Can be integrated with Vault/JWT for secure token auth

ğŸ“ Logs stored with timestamp, score, and mismatch reason

ğŸ§° Developer Tools
Dev Environment
bash
Copy
Edit
poetry install
poetry run uvicorn recon_engine.api.main:app --reload
API Docs
Swagger UI: http://localhost:8000/docs

Redoc: http://localhost:8000/redoc

ğŸ“¦ Future Extensions
ğŸ“ S3 / Snowflake / BigQuery support as sources

ğŸ§  ML-powered anomaly detector module

ğŸ§© Integration with ledger replay engine for real-time validation

ğŸ“¤ Alerts for unmatched records

ğŸ‘¨â€ğŸ’» Author
Built with â¤ï¸ by Vishal, part of the Kairon Infra stack.

ğŸ License
MIT â€” Free to use, modify, and embed in enterprise financial workflows.


